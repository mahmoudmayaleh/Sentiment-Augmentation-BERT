{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "enDIrtJqQGCc",
      "metadata": {
        "id": "enDIrtJqQGCc"
      },
      "source": [
        "\n",
        "### _Enhancing Sentiment Classification on Small Datasets through Data Augmentation and Transfer Learning: A Comparative Study_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kWxg5RrtQcfA",
      "metadata": {
        "id": "kWxg5RrtQcfA"
      },
      "source": [
        "##Notebook Description:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "603df15e",
      "metadata": {
        "id": "603df15e"
      },
      "source": [
        "__The Objective:__ This notebook supports the study _\"Enhancing Sentiment Classification on Small Datasets through Data Augmentation and Transfer Learning\"_. It explores the impact of data augmentation techniques: __Easy Data Augmentation (EDA)__, __NLPaug__ and __Back-Translation__ on sentiment classification performance. Classical machine learning models, including __Logistic Regression__ and __Random Forest__, are trained on both the original and augmented datasets. Additionally, a __BERT__ model is fine-tuned on the original dataset and again on a dataset augmented using NLPaug, leveraging transfer learning. Model performance is evaluated using metrics such as Accuracy, F1-score, and AUC."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xF1rzOml4mY0",
      "metadata": {
        "id": "xF1rzOml4mY0"
      },
      "source": [
        "## Authors:\n",
        "### _Mahmoud Mayaleh_ & _Samer Mayaleh_"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Installing dependencies"
      ],
      "metadata": {
        "id": "mxdyRlbjHO9T"
      },
      "id": "mxdyRlbjHO9T"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a7305de",
      "metadata": {
        "collapsed": true,
        "id": "4a7305de"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn pandas torch transformers\n",
        "!pip install -q nlpaug\n",
        "!pip install googletrans==4.0.0-rc1\n",
        "!pip install --upgrade datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54edd8f3",
      "metadata": {
        "id": "54edd8f3"
      },
      "source": [
        "__Importing Librarys:__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "y8C0Egaao1aP",
      "metadata": {
        "id": "y8C0Egaao1aP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import nlpaug.augmenter.word as naw\n",
        "import random\n",
        "import os\n",
        "import zipfile\n",
        "import nltk\n",
        "import random\n",
        "import re\n",
        "from googletrans import Translator\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, roc_curve\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.nn import CrossEntropyLoss\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from scipy import stats\n",
        "from scipy.stats import t\n",
        "from scipy.optimize import minimize_scalar\n",
        "from torch import amp, cuda\n",
        "from io import StringIO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "an_KBW3DqmhA",
      "metadata": {
        "id": "an_KBW3DqmhA"
      },
      "source": [
        "## Step 2: Dataset preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e2763f7",
      "metadata": {
        "id": "9e2763f7"
      },
      "source": [
        "__Importing Data:__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3f1f625",
      "metadata": {
        "collapsed": true,
        "id": "d3f1f625"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"imdb\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "U0XIGfRVpAlL",
      "metadata": {
        "id": "U0XIGfRVpAlL"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "prbmOd4XpAfy",
      "metadata": {
        "id": "prbmOd4XpAfy"
      },
      "outputs": [],
      "source": [
        "# Sample 5000 entries to simulate a small dataset\n",
        "df_small = df.sample(n=5000, random_state=42)[['text', 'label']]\n",
        "df_small = df_small.rename(columns={'text': 'review'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ugiGVIaykOZy",
      "metadata": {
        "id": "ugiGVIaykOZy"
      },
      "outputs": [],
      "source": [
        "#shuffling data\n",
        "df_small = shuffle(df_small, random_state=42).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NtwVQphwmZ-z",
      "metadata": {
        "id": "NtwVQphwmZ-z"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X_vect = vectorizer.fit_transform(df_small['review'])\n",
        "y = df_small['label'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UacsqKULpr9a",
      "metadata": {
        "id": "UacsqKULpr9a"
      },
      "source": [
        "## Step 3: Train Classical ML Models (Baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1iGKvb2KsIQ_",
      "metadata": {
        "id": "1iGKvb2KsIQ_"
      },
      "source": [
        "Stratified K-Fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YYFti2B0oM8a",
      "metadata": {
        "id": "YYFti2B0oM8a"
      },
      "outputs": [],
      "source": [
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "accuracies = []\n",
        "f1_scores = []\n",
        "train_times = []"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EauekHkIp21R",
      "metadata": {
        "id": "EauekHkIp21R"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DdQV_DBRnHSM",
      "metadata": {
        "id": "DdQV_DBRnHSM"
      },
      "outputs": [],
      "source": [
        "for train_idx, test_idx in kfold.split(X_vect, y):\n",
        "    X_train, X_test = X_vect[train_idx], X_vect[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    model = LogisticRegression()\n",
        "\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    end_time = time.time()\n",
        "\n",
        "    train_duration = end_time - start_time\n",
        "    train_times.append(train_duration)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    accuracies.append(acc)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    print(f\"Fold done. Accuracy: {acc:.4f}, F1: {f1:.4f}, Train Time: {train_duration:.2f} sec\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X0lpTXE9oxil",
      "metadata": {
        "id": "X0lpTXE9oxil"
      },
      "outputs": [],
      "source": [
        "# Confidence Intervals\n",
        "def confidence_interval(data, confidence=0.95):\n",
        "    n = len(data)\n",
        "    mean = np.mean(data)\n",
        "    sem = stats.sem(data)\n",
        "    h = sem * stats.t.ppf((1 + confidence) / 2., n-1)\n",
        "    return mean, h\n",
        "\n",
        "mean_acc, ci_acc = confidence_interval(accuracies)\n",
        "mean_f1, ci_f1 = confidence_interval(f1_scores)\n",
        "print(\"Logistic Regression (Original dataset)\")\n",
        "print(f\"Accuracy: {mean_acc:.4f} ± {ci_acc:.4f}\")\n",
        "print(f\"F1 Score: {mean_f1:.4f} ± {ci_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5Mgn5PTApgmw",
      "metadata": {
        "id": "5Mgn5PTApgmw"
      },
      "outputs": [],
      "source": [
        "for train_idx, test_idx in kfold.split(X_vect, y):\n",
        "    X_train, X_test = X_vect[train_idx], X_vect[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    end_time = time.time()\n",
        "\n",
        "    train_duration = end_time - start_time\n",
        "    train_times.append(train_duration)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    accuracies.append(acc)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    print(f\"Fold done. Accuracy: {acc:.4f}, F1: {f1:.4f}, Train Time: {train_duration:.2f} sec\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9QQMnAA4pnUv",
      "metadata": {
        "id": "9QQMnAA4pnUv"
      },
      "outputs": [],
      "source": [
        "# Confidence Intervals\n",
        "def confidence_interval(data, confidence=0.95):\n",
        "    n = len(data)\n",
        "    mean = np.mean(data)\n",
        "    sem = stats.sem(data)\n",
        "    h = sem * stats.t.ppf((1 + confidence) / 2., n-1)\n",
        "    return mean, h\n",
        "\n",
        "mean_acc, ci_acc = confidence_interval(accuracies)\n",
        "mean_f1, ci_f1 = confidence_interval(f1_scores)\n",
        "print(\"Random Forest (Original dataset)\")\n",
        "print(f\"Accuracy: {mean_acc:.4f} ± {ci_acc:.4f}\")\n",
        "print(f\"F1 Score: {mean_f1:.4f} ± {ci_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Mnhu57SVq2Gp",
      "metadata": {
        "id": "Mnhu57SVq2Gp"
      },
      "source": [
        "## Step 4: Data Augmentation for Small Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3py6G_xPszE7",
      "metadata": {
        "id": "3py6G_xPszE7"
      },
      "outputs": [],
      "source": [
        "print(df_small.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oBfs_BFQpLSr",
      "metadata": {
        "id": "oBfs_BFQpLSr"
      },
      "outputs": [],
      "source": [
        "#Easy Data Augmentation (EDA): (Random Insertion + Random Swap + Random Deletion)\n",
        "\n",
        "def random_deletion(words, p=0.1):\n",
        "    if len(words) == 1:\n",
        "        return words\n",
        "    return [w for w in words if random.random() > p]\n",
        "\n",
        "def random_swap(words, n=1):\n",
        "    new_words = words.copy()\n",
        "    for _ in range(n):\n",
        "        idx1, idx2 = random.sample(range(len(new_words)), 2)\n",
        "        new_words[idx1], new_words[idx2] = new_words[idx2], new_words[idx1]\n",
        "    return new_words\n",
        "\n",
        "def random_insertion(words, n=1):\n",
        "    new_words = words.copy()\n",
        "    for _ in range(n):\n",
        "        idx = random.randint(0, len(new_words)-1)\n",
        "        new_words.insert(idx, new_words[idx])\n",
        "    return new_words\n",
        "\n",
        "def eda(sentence, alpha_rd=0.1, alpha_rs=1, alpha_ri=1):\n",
        "    words = sentence.split()\n",
        "    if len(words) < 4: return sentence\n",
        "    augmented = random_deletion(words, p=alpha_rd)\n",
        "    augmented = random_swap(augmented, n=alpha_rs)\n",
        "    augmented = random_insertion(augmented, n=alpha_ri)\n",
        "    return ' '.join(augmented)\n",
        "#--------------------------------------------\n",
        "\n",
        "df_eda = pd.DataFrame({\n",
        "    'review': df_small['review'].apply(lambda x: eda(x)),\n",
        "    'label': df_small['label']\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zWnNeEg4XShl",
      "metadata": {
        "id": "zWnNeEg4XShl"
      },
      "source": [
        "-----------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iZOxxSevXUFF",
      "metadata": {
        "id": "iZOxxSevXUFF"
      },
      "outputs": [],
      "source": [
        "#Random Insertion/Swap/Deletion using nlpaug\n",
        "aug = naw.RandomWordAug(action=\"swap\")\n",
        "df_nlpaug = pd.DataFrame({\n",
        "    'review': df_small['review'].apply(lambda x: aug.augment(x)),\n",
        "    'label': df_small['label']\n",
        "})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ijuy5FQMbN9k",
      "metadata": {
        "id": "Ijuy5FQMbN9k"
      },
      "source": [
        "---------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hLGU6U1hiCzH",
      "metadata": {
        "id": "hLGU6U1hiCzH"
      },
      "outputs": [],
      "source": [
        "#Back Translation (en-fr-en)\n",
        "def back_translate(text, src='en', tgt='fr'):\n",
        "    try:\n",
        "        if not isinstance(text, str) or not text.strip():\n",
        "            return text\n",
        "        translator = Translator()\n",
        "        translated = translator.translate(text, src=src, dest=tgt).text\n",
        "        back_translated = translator.translate(translated, src=tgt, dest=src).text\n",
        "        return back_translated\n",
        "    except Exception as e:\n",
        "        return text\n",
        "\n",
        "batch_pos = df_small[df_small['label'] == 1].sample(n=300, random_state=42)\n",
        "batch_neg = df_small[df_small['label'] == 0].sample(n=300, random_state=42)\n",
        "batch = pd.concat([batch_pos, batch_neg]).reset_index(drop=True)\n",
        "\n",
        "\n",
        "tqdm.pandas()\n",
        "batch['backtranslated_review'] = batch['review'].progress_apply(lambda x: back_translate(x, src='en', tgt='fr'))\n",
        "\n",
        "\n",
        "df_backtranslation = pd.DataFrame({\n",
        "    'review': batch['backtranslated_review'],\n",
        "    'label': batch['label']\n",
        "\n",
        "})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KnD6h6lxcjxD",
      "metadata": {
        "id": "KnD6h6lxcjxD"
      },
      "source": [
        "--------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Haw0S9qapaAq",
      "metadata": {
        "id": "Haw0S9qapaAq"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "icCwEmpBpdKK",
      "metadata": {
        "id": "icCwEmpBpdKK"
      },
      "outputs": [],
      "source": [
        "df_aug.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N5sUE17DVx9d",
      "metadata": {
        "id": "N5sUE17DVx9d"
      },
      "source": [
        "###  Retrain the model using the original and augmented text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02LeAGZB8yFT",
      "metadata": {
        "id": "02LeAGZB8yFT"
      },
      "outputs": [],
      "source": [
        "def confidence_interval(data, confidence=0.95):\n",
        "    data = np.array(data)\n",
        "    n = len(data)\n",
        "    mean = np.mean(data)\n",
        "    sem = np.std(data, ddof=1) / np.sqrt(n)\n",
        "    ci_bounds = t.interval(confidence, n - 1, loc=mean, scale=sem)\n",
        "    return mean, ci_bounds[0], ci_bounds[1]\n",
        "\n",
        "def evaluate_and_store_metrics_kfold(df, model, model_name, augmentation_name, k=10):\n",
        "    X = [' '.join(text) if isinstance(text, list) else str(text) for text in df['review']]\n",
        "    y = df['label']\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "    accuracies, precisions, recalls, f1s, aucs = [], [], [], [], []\n",
        "    total_time = 0\n",
        "\n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        X_train = [X[i] for i in train_index]\n",
        "        X_test = [X[i] for i in test_index]\n",
        "        y_train = y.iloc[train_index]\n",
        "        y_test = y.iloc[test_index]\n",
        "\n",
        "        pipeline = Pipeline([\n",
        "            ('tfidf', TfidfVectorizer(stop_words='english', max_features=5000)),\n",
        "            ('clf', model)\n",
        "        ])\n",
        "\n",
        "        start = time.time()\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        total_time += time.time() - start\n",
        "\n",
        "        y_pred = pipeline.predict(X_test)\n",
        "        y_prob = pipeline.predict_proba(X_test)[:, 1] if hasattr(pipeline.named_steps['clf'], 'predict_proba') else None\n",
        "\n",
        "        accuracies.append(accuracy_score(y_test, y_pred))\n",
        "        precisions.append(precision_score(y_test, y_pred))\n",
        "        recalls.append(recall_score(y_test, y_pred))\n",
        "        f1s.append(f1_score(y_test, y_pred))\n",
        "        if y_prob is not None:\n",
        "            aucs.append(roc_auc_score(y_test, y_prob))\n",
        "\n",
        "    acc_mean, acc_low, acc_high = confidence_interval(accuracies)\n",
        "    prec_mean, prec_low, prec_high = confidence_interval(precisions)\n",
        "    rec_mean, rec_low, rec_high = confidence_interval(recalls)\n",
        "    f1_mean, f1_low, f1_high = confidence_interval(f1s)\n",
        "    auc_mean, auc_low, auc_high = confidence_interval(aucs) if aucs else (None, None, None)\n",
        "\n",
        "    return {\n",
        "        \"Augmentation\": augmentation_name,\n",
        "        \"Model\": model_name,\n",
        "        \"Accuracy\": acc_mean,\n",
        "        \"Accuracy CI Lower\": acc_low,\n",
        "        \"Accuracy CI Upper\": acc_high,\n",
        "        \"Precision\": prec_mean,\n",
        "        \"Precision CI Lower\": prec_low,\n",
        "        \"Precision CI Upper\": prec_high,\n",
        "        \"Recall\": rec_mean,\n",
        "        \"Recall CI Lower\": rec_low,\n",
        "        \"Recall CI Upper\": rec_high,\n",
        "        \"F1\": f1_mean,\n",
        "        \"F1 CI Lower\": f1_low,\n",
        "        \"F1 CI Upper\": f1_high,\n",
        "        \"AUC\": auc_mean,\n",
        "        \"AUC CI Lower\": auc_low,\n",
        "        \"AUC CI Upper\": auc_high,\n",
        "        \"Training Time (s)\": round(total_time, 2)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KdgtqlM0_siS",
      "metadata": {
        "id": "KdgtqlM0_siS"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "augmentations = [\n",
        "    (df_small, \"Original\"),\n",
        "    (df_eda, \"EDA\"),\n",
        "    (df_nlpaug, \"NLPaug\"),\n",
        "    (df_backtranslation, \"Back-translation\")\n",
        "]\n",
        "\n",
        "models = [\n",
        "    (LogisticRegression(max_iter=1000), \"Logistic Regression\"),\n",
        "    (RandomForestClassifier(n_estimators=100), \"Random Forest\")\n",
        "]\n",
        "\n",
        "for df_aug, aug_name in augmentations:\n",
        "    for model, model_name in models:\n",
        "        results.append(evaluate_and_store_metrics_kfold(df_aug, model, model_name, aug_name))\n",
        "\n",
        "        # Original + Augmented\n",
        "        if aug_name != \"Original\":\n",
        "            df_combined = pd.concat([df_small, df_aug], ignore_index=True)\n",
        "            results.append(evaluate_and_store_metrics_kfold(df_combined, model, model_name, f\"Original + {aug_name}\"))\n",
        "\n",
        "results_df = pd.DataFrame(results).round(4)\n",
        "results_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q1p-cCwvmyS3",
      "metadata": {
        "id": "Q1p-cCwvmyS3"
      },
      "outputs": [],
      "source": [
        "# Raw results table as a CSV-style string\n",
        "data = \"\"\"Augmentation,Model,Accuracy,Accuracy CI Lower,Accuracy CI Upper,Precision,Precision CI Lower,Precision CI Upper,Recall,Recall CI Lower,Recall CI Upper,F1,F1 CI Lower,F1 CI Upper,AUC,AUC CI Lower,AUC CI Upper,Training Time (s)\n",
        "Original,Logistic Regression,0.8540,0.8452,0.8628,0.8382,0.8263,0.8501,0.8757,0.8640,0.8873,0.8564,0.8480,0.8647,0.9317,0.9238,0.9397,7.55\n",
        "Original,Random Forest,0.8254,0.8160,0.8348,0.8422,0.8262,0.8581,0.7992,0.7863,0.8121,0.8199,0.8108,0.8289,0.9068,0.8981,0.9154,49.40\n",
        "EDA,Logistic Regression,0.8480,0.8357,0.8603,0.8329,0.8182,0.8477,0.8688,0.8515,0.8861,0.8503,0.8379,0.8627,0.9269,0.9154,0.9384,6.87\n",
        "Original + EDA,Logistic Regression,0.9079,0.9002,0.9156,0.8961,0.8864,0.9058,0.9217,0.9127,0.9307,0.9087,0.9011,0.9162,0.9678,0.9637,0.9718,13.01\n",
        "EDA,Random Forest,0.8286,0.8186,0.8386,0.8513,0.8367,0.8660,0.7944,0.7781,0.8107,0.8216,0.8110,0.8322,0.9076,0.8964,0.9188,47.30\n",
        "Original + EDA,Random Forest,0.9800,0.9761,0.9839,0.9798,0.9735,0.9860,0.9801,0.9751,0.9850,0.9799,0.9760,0.9838,0.9977,0.9969,0.9985,106.50\n",
        "NLPaug,Logistic Regression,0.8540,0.8452,0.8628,0.8382,0.8263,0.8501,0.8757,0.8640,0.8873,0.8564,0.8480,0.8647,0.9317,0.9238,0.9397,7.37\n",
        "Original + NLPaug,Logistic Regression,0.9135,0.9078,0.9192,0.9019,0.8942,0.9095,0.9270,0.9179,0.9360,0.9142,0.9084,0.9199,0.9701,0.9651,0.9752,13.44\n",
        "NLPaug,Random Forest,0.8308,0.8183,0.8433,0.8485,0.8359,0.8611,0.8032,0.7811,0.8254,0.8249,0.8107,0.8392,0.9094,0.9001,0.9188,48.49\n",
        "Original + NLPaug,Random Forest,0.9820,0.9761,0.9879,0.9838,0.9788,0.9889,0.9799,0.9716,0.9881,0.9818,0.9759,0.9878,0.9989,0.9982,0.9997,100.41\n",
        "Back-translation,Logistic Regression,0.7650,0.7220,0.8080,0.7533,0.7025,0.8040,0.7967,0.7434,0.8499,0.7722,0.7314,0.8130,0.8571,0.8219,0.8923,1.87\n",
        "Original + Back-translation,Logistic Regression,0.8657,0.8580,0.8735,0.8501,0.8414,0.8587,0.8865,0.8716,0.9015,0.8678,0.8597,0.8759,0.9396,0.9328,0.9465,8.12\n",
        "Back-translation,Random Forest,0.7600,0.7175,0.8025,0.7667,0.7021,0.8313,0.7667,0.6864,0.8469,0.7600,0.7139,0.8062,0.8302,0.7991,0.8613,5.01\n",
        "Original + Back-translation,Random Forest,0.8464,0.8391,0.8538,0.8674,0.8596,0.8753,0.8162,0.7988,0.8335,0.8408,0.8320,0.8496,0.9278,0.9229,0.9327,54.73\n",
        "\"\"\"\n",
        "\n",
        "results_df = pd.read_csv(StringIO(data))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Xpx9Ya3e51Wo",
      "metadata": {
        "id": "Xpx9Ya3e51Wo"
      },
      "source": [
        "## Step 5: Transfer Learning - __BERT__ (Original Dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-IpFUL1x3afv",
      "metadata": {
        "id": "-IpFUL1x3afv"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rHiOapz-54eQ",
      "metadata": {
        "id": "rHiOapz-54eQ"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "X_train_list = X_train.tolist()\n",
        "X_test_list = X_test.tolist()\n",
        "\n",
        "def tokenize_data(texts):\n",
        "    return tokenizer(texts, padding=True, truncation=True, max_length=256, return_tensors='pt')\n",
        "\n",
        "X_train_tokenized = tokenize_data(X_train_list)\n",
        "X_test_tokenized = tokenize_data(X_test_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ia2ucP_A6eWe",
      "metadata": {
        "id": "ia2ucP_A6eWe"
      },
      "source": [
        "I will use the pre-trained BERT model and add a classification layer on top for sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YFM4vAcw6g-3",
      "metadata": {
        "id": "YFM4vAcw6g-3"
      },
      "outputs": [],
      "source": [
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "\n",
        "train_data = TensorDataset(X_train_tokenized['input_ids'], X_train_tokenized['attention_mask'], torch.tensor(y_train.values))\n",
        "test_data = TensorDataset(X_test_tokenized['input_ids'], X_test_tokenized['attention_mask'], torch.tensor(y_test.values))\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3LPbSTgE_xAQ",
      "metadata": {
        "id": "3LPbSTgE_xAQ"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/aug_models/bert_finetuned_model65.pt'))\n",
        "model.to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "\n",
        "weights = torch.tensor([1.0, 1.0]).to(device)\n",
        "loss_fn = CrossEntropyLoss(weight=weights)\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch in tqdm(train_dataloader):\n",
        "        input_ids = batch[0].to(device)\n",
        "        attention_mask = batch[1].to(device)\n",
        "        labels = batch[2].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = running_loss / len(train_dataloader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            labels = batch[2].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(test_dataloader)\n",
        "    val_losses.append(avg_val_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/aug_models/bert_finetuned_model70.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2xx9bB9q0iga",
      "metadata": {
        "id": "2xx9bB9q0iga"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), \"bert_sentiment_model.pt\")\n",
        "from google.colab import files\n",
        "files.download(\"bert_sentiment_model.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Kf5SBSV72Stq",
      "metadata": {
        "collapsed": true,
        "id": "Kf5SBSV72Stq"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/aug_models/bert_finetuned_model70.pt'))\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5Xv1WJTHAYuB",
      "metadata": {
        "id": "5Xv1WJTHAYuB"
      },
      "source": [
        "## Step 6: Transfer Learning - __BERT__ (__NLPaug__) - different seeds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "D0pzr-_4jPeC"
      },
      "id": "D0pzr-_4jPeC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 127\n",
        "num_epochs = 50\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "df = pd.concat([df_small, df_nlpaug])\n",
        "texts = df['review'].astype(str).tolist()\n",
        "labels = df['label'].values\n",
        "\n",
        "device = torch.device(\"cuda\" if cuda.is_available() else \"cpu\")\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def tokenize_data(texts):\n",
        "    return tokenizer(texts, padding=True, truncation=True, max_length=256, return_tensors='pt')\n",
        "\n",
        "encoded = tokenize_data(texts)\n",
        "input_ids = encoded['input_ids']\n",
        "attention_mask = encoded['attention_mask']\n",
        "labels_tensor = torch.tensor(labels)\n",
        "\n",
        "train_idx, temp_idx = train_test_split(np.arange(len(labels)), test_size=0.2, stratify=labels, random_state=SEED)\n",
        "val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, stratify=labels[temp_idx], random_state=SEED)\n",
        "\n",
        "def create_loader(indices, batch_size=16, shuffle=True):\n",
        "    dataset = TensorDataset(input_ids[indices], attention_mask[indices], labels_tensor[indices])\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=2, pin_memory=True)\n",
        "\n",
        "train_loader = create_loader(train_idx)\n",
        "val_loader = create_loader(val_idx, shuffle=False)\n",
        "test_loader = create_loader(test_idx, shuffle=False)\n"
      ],
      "metadata": {
        "id": "A1yU1aVCH1Dw"
      },
      "id": "A1yU1aVCH1Dw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9yfsOum1AYL4",
      "metadata": {
        "id": "9yfsOum1AYL4",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "loss_fn = CrossEntropyLoss()\n",
        "scaler = amp.GradScaler(device=device.type)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
        "        input_ids_b = batch[0].to(device)\n",
        "        attention_mask_b = batch[1].to(device)\n",
        "        labels_b = batch[2].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with amp.autocast(device_type=device.type):\n",
        "            outputs = model(input_ids=input_ids_b, attention_mask=attention_mask_b, labels=labels_b)\n",
        "            loss = outputs.loss\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "    scheduler.step()\n",
        "\n",
        "    model.eval()\n",
        "    val_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        val_loss, correct, total = 0.0, 0, 0\n",
        "        for batch in val_loader:\n",
        "            input_ids_b = batch[0].to(device)\n",
        "            attention_mask_b = batch[1].to(device)\n",
        "            labels_b = batch[2].to(device)\n",
        "\n",
        "            with amp.autocast(device_type=device.type):\n",
        "                outputs = model(input_ids=input_ids_b, attention_mask=attention_mask_b)\n",
        "                logits = outputs.logits\n",
        "\n",
        "            loss = loss_fn(logits.float(), labels_b)\n",
        "            val_loss += loss.item() * labels_b.size(0)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            correct += (preds == labels_b).sum().item()\n",
        "            total += labels_b.size(0)\n",
        "\n",
        "    avg_loss = val_loss / total\n",
        "    accuracy = correct / total\n",
        "    print(f\"Epoch {epoch+1} | Val Loss: {avg_loss:.4f} | Val Acc: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Total time: {(end_time - start_time)/60:.2f} minutes\")\n",
        "\n",
        "torch.save(model.state_dict(), f'/content/drive/MyDrive/bert_model/seed/bert_seed{SEED}-50.pt')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate BERT"
      ],
      "metadata": {
        "id": "uJzU42biigut"
      },
      "id": "uJzU42biigut"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate BERT (Original)"
      ],
      "metadata": {
        "id": "Pwc2i__vJV3Y"
      },
      "id": "Pwc2i__vJV3Y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KLw28xPQ5ua3",
      "metadata": {
        "id": "KLw28xPQ5ua3"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "all_preds, all_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "print(\"70 epochs\")\n",
        "print(classification_report(all_labels, all_preds))\n",
        "print(\"AUC:\", roc_auc_score(all_labels, all_preds))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mp4mghmDUDP-",
      "metadata": {
        "id": "mp4mghmDUDP-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = [5, 10, 20, 35, 50, 60, 65, 70]\n",
        "accuracy = [0.51, 0.51, 0.59, 0.78, 0.85, 0.87, 0.87, 0.88]\n",
        "auc = [0.506, 0.506, 0.594, 0.782, 0.853, 0.870, 0.869, 0.877]\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(epochs, accuracy, label=\"Accuracy\", marker='o', color='b', linestyle='-', linewidth=2, markersize=8)\n",
        "plt.plot(epochs, auc, label=\"AUC\", marker='o', color='r', linestyle='-', linewidth=2, markersize=8)\n",
        "\n",
        "plt.title(\"Model Performance over Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.legend()\n",
        "\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9Aypoo8n-TEa",
      "metadata": {
        "id": "9Aypoo8n-TEa"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_losses, label=\"Train Loss\")\n",
        "plt.plot(val_losses, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Train vs Validation Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate BERT (Original + NLPaug)"
      ],
      "metadata": {
        "id": "sj0uygYUKLgm"
      },
      "id": "sj0uygYUKLgm"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "df = pd.concat([df_small, df_nlpaug])\n",
        "texts = df['review'].astype(str).tolist()\n",
        "labels = df['label'].values\n",
        "\n",
        "def tokenize_data(texts):\n",
        "    return tokenizer(texts, padding=True, truncation=True, max_length=256, return_tensors='pt')\n",
        "\n",
        "encoded = tokenize_data(texts)\n",
        "input_ids = encoded['input_ids']\n",
        "attention_mask = encoded['attention_mask']\n",
        "labels_tensor = torch.tensor(labels)\n",
        "\n",
        "train_idx, temp_idx = train_test_split(np.arange(len(labels)), test_size=0.2, stratify=labels, random_state=0)\n",
        "val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, stratify=labels[temp_idx], random_state=0)\n",
        "\n",
        "test_dataset = TensorDataset(input_ids[test_idx], attention_mask[test_idx], labels_tensor[test_idx])\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "model_paths = {\n",
        "    12: \"/content/drive/MyDrive/bert_model/seed/bert_seed12-50.pt\",\n",
        "    44: \"/content/drive/MyDrive/bert_model/seed/bert_seed44-50.pt\",\n",
        "    127: \"/content/drive/MyDrive/bert_model/seed/bert_seed127-50.pt\"\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for seed, path in model_paths.items():\n",
        "    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "    model.load_state_dict(torch.load(path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    all_preds, all_probs, all_labels = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids_b = batch[0].to(device)\n",
        "            attention_mask_b = batch[1].to(device)\n",
        "            labels_b = batch[2].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids_b, attention_mask=attention_mask_b)\n",
        "            logits = outputs.logits\n",
        "            probs = torch.softmax(logits, dim=1)[:, 1].cpu().numpy()\n",
        "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "\n",
        "            all_preds.extend(preds)\n",
        "            all_probs.extend(probs)\n",
        "            all_labels.extend(labels_b.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds)\n",
        "    auc = roc_auc_score(all_labels, all_probs)\n",
        "\n",
        "    results[seed] = {'Accuracy': acc, 'F1': f1, 'AUC': auc}\n",
        "\n",
        "# Results Table\n",
        "df_results = pd.DataFrame(results).T\n",
        "df_results.index.name = \"Seed\"\n",
        "df_results.reset_index(inplace=True)\n"
      ],
      "metadata": {
        "id": "07YxrDLTinoM"
      },
      "id": "07YxrDLTinoM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_results"
      ],
      "metadata": {
        "id": "-B1o7Tsoo9u2"
      },
      "id": "-B1o7Tsoo9u2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_methods = results_df[results_df['Augmentation'].str.startswith('Original')]\n",
        "\n",
        "mean_acc_combined = combined_methods.groupby('Augmentation')['Accuracy'].mean()\n",
        "\n",
        "bert_mean_acc = 0.995\n",
        "bert_acc = 0.88\n",
        "mean_acc_combined['BERT (Original + NLPaug)'] = bert_mean_acc\n",
        "mean_acc_combined['BERT (Original)'] = bert_acc\n",
        "\n",
        "mean_acc_combined = mean_acc_combined.sort_values()\n",
        "\n",
        "colors = ['blue' if 'BERT' in str(key) else 'gray' for key in mean_acc_combined.index]\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "mean_acc_combined.plot(kind='bar', color=colors)\n",
        "\n",
        "plt.title('Mean Accuracy: Combined Augmentation Methods vs. BERT')\n",
        "plt.ylabel('Mean Accuracy')\n",
        "plt.ylim(0.7, 1)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"combined_augmentation_vs_bert_accuracy.png\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ooHWMBIZt13Y"
      },
      "id": "ooHWMBIZt13Y",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "mxdyRlbjHO9T",
        "an_KBW3DqmhA",
        "UacsqKULpr9a",
        "Mnhu57SVq2Gp",
        "N5sUE17DVx9d",
        "Xpx9Ya3e51Wo",
        "5Xv1WJTHAYuB",
        "uJzU42biigut",
        "Pwc2i__vJV3Y",
        "sj0uygYUKLgm"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}